* Main Project TODOs
** TODO Speed up BFS / check why it fails 
   We have duplicates in our queue, and it would be nice to get rid of these so we can speed up the computation and blah blah blah. 

   Unfortunately, this is causing some false negatives. Need to check why this happens too. Lol!!!!! 
** TODO Fix bug with transducer intersection 
   It seems that there's something not going right with conjunctions. 
   We are getting a false negative, when there is indeed a path that we can take. 

   Still got no idea about this one, sorry me
** TODO Fix bug with accessibility, for H-O knowledge

   Looks like the beast is back but in a different form. I think the problem is is that we're comparing knowledge *after* the call has been made, when 
   we really want to compare it before. This is a bit difficult.... 
   Actually it seems that we should just be able to filter the set of possible states based on the predicate we give it. Hence we only look at the states 
   satisfy the predicate ??? 
*** S-O Knowledge
   The problem seems to be that our relation does not care about the protocol we are using; i.e., it will let an agent perceive that a call happens which cannot actually happen. This is especially noticeable when using the protocol LNS. 

   We should be able to fix this. We can either:
   - Change the way the call transducer works; that is, pass in the protocol into the transducer composition function. This is not particularly appealing. 
   - Check that a call is permissible by the protocol before we make it. This is a bit nicer as we have access to the protocol when constructing the PSA and so can use it in the definition of the transitition function.
   

   The thing seems to be that we should only let two states be related after a call if the knowledge states for each call member were the same before we started the call. Intuitively, this is because an agent b *can* distinguish between two worlds where he knows different things, or the callee knows two different things. 

   The question now is how to implement this. We use the transducer approach to relate calls, which just tells us the calls that are indistinguishable from our current state. Do we perhaps need to look at the true state more?  

   We need to change the single-state transducer to only relate a state-call pair with another state-call pair iff the states have the same knowledge for the agents involved in the call. The best way to do this is most likely to give our PSA some "special case" function for inputs (q, e) x (q, e). This will tell them if the transition we want to make is acceptable under some special rule we enforce; for example, here it would be that if the agent is involved in the call, we better have that the knowledge states for each agent in the call are identical.  
*** H-O Knowledge
    Okay, so here we have the same issue as before. Some false positives are happening. Probably we can just do as before, by getting the world pointed to and checking that this transition is OK to make.  
** TODO Add in automated testing
   It feels like we need to try and use an automated system to profile the code; it looks like certain solutions take longer to reach than others. 
   
*** TODO Open Issue & PR on Malvin's Gossip GH page
    This will fix the issue I had about restrictKey not building. 
*** DONE Conversion to Gattinger style
    CLOSED: [2019-03-27 Wed 14:21]
    It should be fairly straightforward to convert to and from the style that Malvin uses for his Gossip checker. His stores the initial states as just lists of lists of numbers; e.g. 

   [[0,1],[1,2],[2],[1,3]

   means that a and d know b's number, b knows c's number, and c knows no-ones number. 
   We can then convert our calls in a very similar way; his are just pairs of numbers. Finally, we can use his update function to verify that the winning condition is satisfied after the set of calls we provide. 
*** DONE Connect the two projects
    CLOSED: [2019-03-27 Wed 17:00]
    Next, we need to find out how we can use Malvin's package from ours.
    This might be a bit tricky. There may not be a straightforward way to just stick in the part that we want ... 
*** DONE Add in automated testing framework
    CLOSED: [2019-03-28 Thu 20:23]
    We want it to generate all of the possible gossip graphs, and then verify them in Malvin's software. 
    What will this consist of? 

    - We want to give it the *size* and the *number of tests*.
    - Then it finds a load of graphs that we can use. Possibly this could be random? But for now, let's just use `take`.  
    - Then finally we just want to find a call path that takes us to the end, and then validate that this works using Malvin's code. 
    - We also need to be able to convert the winning conditions betwen the two different languages. This could perhaps come second though.

    We also can't forget that we need to be able to test that our negative responses are truly negative; this can be done by using Malvin's 
    statistics function and checking that he says that there are no incorrect paths. 
*** DONE Add in emptiness testing
    CLOSED: [2019-03-29 Fri 10:40]
    Essentially, we just want a way to check that when we cannot find a path, we truly cannot find a path. 
    To do this, we can use Malvin's code. Most likely, we want to use *`sequences`* to find the set of all sequences; then, we want to use *`statistics`* to check that none of these sequences are successful.

    An issue is that Malvin's code is very happy to produce endless sequences. This is no good for verification. To this end, we should stop sequences from being too long and just cut them off at a certain point. This is also a nice way to show off laziness ... 
*** TODO Convert between the two ways of encoding winning conditions. 
*** Using QuickCheck 
    It seems that all we need to do to use QuickCheck to test our program is to define an Arbitrary instance for the type of initial graphs. This should just mean using the functions in the MakeGraphs file. 
    This might be a bit of overkill though; plus, with ours, we can easily specify the size of the graph we want. 
** TODO Add some kind of copyright thing regarding Malvin's stuff 
** TODO Change structure (use typeclass instead of QState subtypes)
   This would do little more than just clean up the code. I would be surprised if this gave us a notable improvement in time or something. 
** TODO Think about different knowledge models 
   Muddy children? This could be really neat
   
*** Jan van Eijck DEMO-S5
    In this paper, JvE has his models be parametric in what they store as the state. This is cool, and this is something that we can implement too in ours. 

    It'squite likely that we will have to also add in our own language of propositions. We can probably use the same family of formulas, but the set of propositions that we use will need to change as we use different knowledge models.

    We also need to think about how to handle the updating of information with an epistemic model and an event model.

    Muddy Children seems to be the same kind of situation; we have a specialised Epistemic model and we update this model through event models. 
    The primary points of attack will be: 
**** DONE Make Epistemic Models parametric
     CLOSED: [2019-04-01 Mon 17:44]
     By this, I mean that the Models take some type and these types become the States of our new model. So we have a set of them, and also they're used in valuation and initial. 
**** TODO Look at what can be done for event models?
     Chapter 6 of DEMO-S5 will be helpful to this end 
**** TODO Change the language of propositions to also be parametric
** DONE Fix bug w/ H-O knowledge
   CLOSED: [2019-03-31 Sun 17:42]
   * The issue seems to be that when we go through a second-order automata, the states are not updated with the correct indisgintuishable calls, but the formula being evaluated is the correct one. This is most likely where the issue is. 
     So to fix this, we need to change the way that the automata transitions work? 
   * It seems that now this isn't the problem; calls were going along fine, but the initial setup did not allow for any other calls to occur. This leads us to the realisation that, in order to reasonably work, *the agents will have complete knowledge of the graph layout before starting*. This is definitiely in need of being mentioned in report.
   * It looks like maybe we get a negative response when we can't ever know for sure that the thing holds. For the test case P (N a b), P (N d c), P (N d a)] we are successful; it clearly just depends on if we can actually get to a position that is successful. This is good news for us!

   * TODO: Investigate why we are successful for {N a b, N d c, N d a} but not {N a b, N b c, N d c, N d a}. 
** DONE Look at running Haskell on blue crystal
   CLOSED: [2019-03-27 Wed 14:22]
   Mainly to the end of just getting it off my machine. Probs way quicker ...
   This really doesn't seem like a good idea any more. . . 

** DONE Look into using a priority queue for the queue               :search:
   CLOSED: [2019-03-26 Tue 14:33]
   The memory bottleneck is still enqueue. PQueues will give us O(log n) delete-min and O(log n) insert; this is better than the O(1) deletion and O(n) insertion currently.

   Will this really be cheaper though? We need to perform m insertions, where m is the length of the new items list. Then We perform O(m * logn) operations, whereas for appending the list we just do O(n). 

   There may be a better alternative; for example, [[http://hackage.haskell.org/package/containers-0.6.0.1/docs/Data-Sequence.html][sequences]]. These have constant-time appending -> O(m) append. This is obviously better than O(m log n), but it won't always be better than O(n). . .

  *OR* We can just use a normal Queue? You dummy !!!! *UPDATE*: Normal queues were deprecated for sequences.
** DONE Write program to generate gossip graphs for use in testing
   We will have to just use the pre-defined event models, as there's no point testing using inappropriate event models.
   Then, this just amounts to generating graphs. Perhaps we just want to generate every possible graph and see what happens from there on?
   This is because the set of agents is fixed (we can e.g. give this as input), the accepting state is latex fixed... The initial state is the important factor. 
   This testing strategy is probably going to be important for marking, so need to think rather heavily about this. 
** DONE Research benchmarking
** DONE Higher-order Knowledge
   This will consist of using our single point of entry to build an
   automata that lets us find a path to a HO formula. This kinda just depends on the above!
   
** DONE Provide single point of entry
   By this, I mean that we give a single `build` function or something that takes a certain 
   proposition and then creates the automata w/ paths to the goal.
   
   This will need some thinking on what order to do certain automata processes once it's
   open - i.e. creating states, setting winning formula, etc

   This is now done for a non-knowledge formula, but we still need to get something working
   for HO knowledge. Should just be a case of recursively doing the buildPSA process?
   
*** Tests
    * Check that we get a behaviour as we did before for all of the basic cases
    * Test that things work for FO
    * And then Higher-order. Most likely if it works or SO, we get Higher Order

*** TODO On Conjunction / Disjuncton
    It seems that the simplest way to use a conjunction / disjunction will be to 
    do automata union & disjunction respectively. These are very standard procedures!
    We can just then build an automata for every knowledge formula and perform this 
    operation on them. 

    However, the subtlety might be in when we want to do this. E.g if our conjunction
    is for not knowledge-formulas, we can just stick it all into one automata. 

    We're faced with a problem when doing transitions. To fix this, it seems that 
    we should add in a new constraint to states such that they have a "fail"; this 
    is what we can move to in the case of a non - transition. 

    Update: It's simpler to just do intersection first, as we fail if any of the states 
    made a "no-transition". Then in order to do union we can just use de Morgan's law
** DONE Handle OR
   CLOSED: [2019-03-20 Wed 11:31]
* Benchmarking and Testing

  Remember that Steven said that Meng likes automated testing; it would be cool to have an automated way to test all of these things.  
  Perhaps we should just run all of the generated graphs, somehow check that they are correct (e.g. against Malvin gattinger's?) and then use the total profiling information to analyse. 

** Comparisons

   It would be good to find some other examples of software that does the same job as we're trying to do, and then compare our runtime and space usage against theirs. Even if this means just to compare against our own previous times.
   Such examples are the gattinger one, and the JVE one. 

   Either we can check results as we go along, or we can store the results in another file and then put them into the other checkers. The latter is a bit preferable, as it means we can just profile the first on its own and then not time the comparison in with it. However the latter is inevitably more difficult. 

** GHC Profiling

   GHC has profiling built in; this is very nice; [[https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html][here is the link]]. 
   It gives us a breakdown of where most of the time is spent during the tests. This means we can improve the program by making the bottlenecked areas more efficient.

   To save time in the future:
   
   - Compile with 
         `ghc -prof -fprof-auto -O2 -w -rtsopts Main.hs`
     -w removes all the pesky warnings
   - Run with 
         `./Main +RTS -p -RTS`

** Profiling Runs
*** One - First - 20/3 

    +------+-------+-----------+
    | Size | Order | Runtime/s |
    |------+-------+-----------|
    |    3 |     0 |      0.00 |
    |    4 |     1 |      68.3 |
    |    4 |     1 |      64.2 |
    +------+-------+-----------+

    Through profiling, we clearly see that we spend most of our time in the doBFS function. This makes perfect sense.
    Further down, we see that in here nearly all of our time is spent within updateQueue. This is a much more interesting issue to have. 
    In this, a lot of time is spent computing the neighbours and also enqueueing information. 

    - A whole 40.7% of the time is spent comparing what I think are just states, when we check if an element is in the set of seen nodes. It's kind of unclear to me how we can reduce this; there doesn't seem to be any way to reduce the time spent doing comparisons. 
      - Perhaps we can change from using a list to using a set? Sets have quicker lookup time but also longer input time. This may be advantageous though.
      - We could also change some part of the program to guarantee that we can't revisit another state - e.g. by setting all of the visited states to be null?

*** Two - First Major Speedup - 22/3 
    
    The first huge improvement in time was the change from folding with the enqueueOne function to filtering the set of items incident on the function and just appending them on. 

    The main reason for this improvement is the way that it's implemented; previously, we were concatenating the item onto the end of the list. 
    List concatenation is linear time, as we have to walk through the whole list and then stick a pointer to the next element on at the end. Instead, we filter which is linear in the size of the items list, and then append this. This is much faster. 

    After this:

  +------+-------+--------+
  | Size | Order | Time/s |
  |------+-------+--------|
  |    5 |     1 |    234 |
  |    5 |     0 |   0.34 |
  |      |       |        |
  +------+-------+--------+

*** Three - Second speedup - 22/3, Later
    
    Next big old speedup was changing use of lists to using Sets. Much faster than list. Should document speedup when I get around to it 
    This happened because membership checking on lists is O(n) time. This is obviously not very good. Furthermore, list appending is O(n). Insertion and membership checks for Sets are always O(log n). So we get a big speedup nearly for free!

   It seems that for now the main bottleneck of time is the function models. As for memory, it seems that produceAllProps is causing 23.4% of the memory allocation; perhaps we can do this lazily?

*** Four - DLists vs No Dlists - 23/3

   *These are for using dlists in BFSM*
  +------+-------+--------+--------+
  | Size | Order | Time/s | Memory |
  |------+-------+--------+--------|
  |      |       |        |        |
  |    5 |     0 |   4.34 | 2Gb    |
  |    5 |     1 |  27.44 | 15.4Gb |
  |    4 |     1 |   0.12 | 51Mb   |
  +------+-------+--------+--------+

  *And these are for without DLists*
  +------+-------+--------+--------+
  | Size | Order | Time/s | Memory |
  |------+-------+--------+--------|
  |    6 |     0 |        |        |
  |    5 |     0 |   9.18 | 10.4Gb |
  |    5 |     1 |  11.44 | 11Gb   |
  |    4 |     1 |   0.04 | 15Mb   |
  +------+-------+--------+--------+

  Regardless of this, one bottleneck for sure is the `models` function. 
  To speed this up, we can also change this to a set. Again, `elem` is O(n), 
  and we can afford to take a hit on the speed of insertion to speed up lookups.

*** Five - Changing to Sets - 23/3

| Size | Order | Time/s | Memory |
|------+-------+--------+--------|
|    5 |     1 |  16.77 | 12.7Gb |
|    5 |     0 |  11.51 | 11.4Gb |
|      |       |        |        |
*** Six - Change models to ListModels - 26/3
| Size | Order | Time/s | Memory |
|------+-------+--------+--------|
|    5 |     1 |  10.86 | 12.4Gb |
|      |       |        |        |
|      |       |        |        |
*** Seven - Change queue to Sequence - 26/3

| Size | Order | Time/s | Memory |
|------+-------+--------+--------|
|    5 |     1 |  20.38 | 12.0Gb |
|    5 |     0 |  18.44 | 10.9Gb |
|      |       |        |        |

This is a weird result, as we suddenly lose all of the enqueue time from the profile, yet total time increases. 

* Existing Software
** Gattinger - Gossip
   Gattinger's software will generate the set of possible call strings through a gossip graph. It then checks which of these are successful or not. This is a slightly different function to ours of course, but at its heart is the same. 

   A key thing to check is to see whether or not it works for epistemic winning conditions; and if so, if it's performant doing this. Not only would this be good software to compare against, but also to see test with. 

   It seems that we can, and in a very straightforward way! A query looks like this;

   eval (graph3, [(0, 1), (0, 2), (0, 1)]) (K 0 anyCall allExperts)

   Weirdly we need to put the protocol into the epistemic operator, but that is okay!
   

* Optimisations & Improvements
** QState / PState
   Essentially 
       PVar (Q [N a b])  
   seems really dumb; there's definitely a better way to do this. Most likely just cut out the Q in the middle and make it PVar [N a b]... 
* Other Knowledge Models
** Muddy Children

   The muddle children problem is in which we have a bunch of children who are outside playing in the mud. They come back inside, and their mother tells them 
     "At least one of you has mud on your head"

    The children can't see their own head, but can see the mud on the foreheads of others. She asks the following question over and over: 
     "Can you tell for sure whether or not you have mud on your head?"

    This can be modelled in our system, by letting the children be agents and announcements (or, not announcements) to their mother's question be events. 
    
* Poster Talk
  Remember that our talk should just cover how we solve the problem, and not really go into detail on *how*.
  
  * *First define the prolem.*
    - The Gossip Problem regards peer to peer information sharing. We start with a group of agents, each of whom have some secret information. 
    - Agents exchange calls through phone calls; they tell the other agent all of the information they know, which are just the secrets and phone numbers of other agents. 
    - We want to find sequences of calls that take us to a certain winning state. For now, let this just be the state in which every agent is an expert - that is, every agent knows the secret of every other agent.

  * *Now introduce how we solve it.*
    - DEL for representation (as on the poster). 
    - Then we construct an automata whose nodes are knowledge states and edges are telephone calls between agents. 
    - In order to solve the problem, we just need to find a path through the automata that takes us from some initial state to an accepting state, which we update to be states at which our winning condition holds
    - This automatic representation is really great, as it lets us perform operations like intersection and complement. 

  * *Then, let's talk about Knowledge* 
    - We can make the problem a lot more interesting if we start to look for states where agents know certain things. 
    - We reason about this by inspecting all of the states that the agent considers possible at a given world. If a formula holds at all worlds indistinguishable from a certain world, then the agent knows that the formula holds at the world. 
    - We then build a transducer that relates calls that are indistinguishable from one another; for example, agent a cannot distinguish between a call from agent b to c or agent d to c. 
    - Next, we step through our automata from earlier and the transducer simulatenously; thus building up a set of the states that are indistinguishable from our current state. 
    - This lets us evaluate a formula like "a knows that everyone is an expert" in constant time; we just need to look at all of the states that are indistinguishable from our current one and check that everyone is an expert in these. This is much quicker than if we had to find these states some other way. 
    - We can just repeat this process for higher-order knowledge, like 'everyone knows that everyone knows that everyone is an expert'
