\documentclass[12pt, a4paper]{article}

\input{preamble.tex}

\title{Protocol Synthesis in the Dynamic Gossip Problem} % The article title

\author{
	\authorstyle{Leo Poulson}
	\newline\newline % Space before institutions
}

\date{\today}

\begin{document}

\maketitle
\thispagestyle{firstpage}

\section{Introduction}

\subsection{Motivation}

\subsubsection{The Gossip Problem} 
The gossip problem is a problem regarding peer-to-peer information sharing. A
set of agents start out with some secret information, and their goal is to
transfer this information across the whole network, thus finding out the secret
of all of the other agents. This information is transferred through a phone call
from one agent to another. When two agents communicate they tell each other all
the secrets that they know; hence the name \textit{gossip}. %This process of
% gossiping is heavily used in networks, and the investigation of epidemic
% information spreading. \textbf{add citations}.

In the original problem formulation (\cite{Tijdeman:1971}), each agent began
with the phone number of every other agent, and hence the starting network is a
complete graph. Recently, there has been a lot of work in studying a variation
of this problem named the \textit{dynamic} gossip problem. In this, the agents
start out with an incomplete set of phone numbers, and as they call the other
agents, they exchange all of the phone numbers they know and so the graph's
edges grow in number.

The dynamic gossip problem is a popular research topic (\cite{DynamicGossip},
\cite{EpProforDyGo}), with applications in work in epidemics and research
discoverd (\cite{DiscoverythruGossip}) \textbf{Add more references.}. In such
scenarios, our network may be some peer to peer network, with our agents as
computers and the goal to be finding the IP addresses of all of the other
computers; or our network might be a social network, where we have people as
agents who want to connect with everyone around them. In both cases, our network
is updated as the agents communicate and they learn the contact details of other
agents.

\textbf{Applications of DEL here \ldots}

There are several existing implementations of model checkers for epistemic logic
and gossip problems; three of them are \cite{DEMO-S5}, \cite{GithubGossip},
\cite{SMCDEL}. The three all differ in implementation style, but they all aim to
solve the same problem; given some system with an initial state and a way to
move between states, what events can occur to take the system from its initial
state to a successful one? \cite{GithubGossip} aims to give the user the events
required to take the system to the state, whereas the other two aim to tell the
user if a string of events given are successful. 

\subsubsection{Planning}

Automated planning is the act of computing a finite sequence of actions to take
some system from a given initial state to some successful state. Recently, a
variant of this has been studied by the dynamic epistemic logic community,
called \textit{epistemic} planning. Given an initial set of knowledge states of
a set of agents, a finite set of available events, and an epistemic objective,
the epistemic planning problem consists of computing the finite sequence of
events whose occurence takes us from the initial state to a state satisfying the
epistemic objective.

This problem is undecidable for many cases (\cite{UndecidabilityEP}), but by placing
certain restrictions on the models we use it becomes decidable.

\subsubsection{Model Checking}

\subsection{Contributions}

In this thesis, we put forward a process to solve the decidable epistemic planning
problem. We also give an implementation of this process in Haskell. This process
also will solve the gossip problem, by finding a sequence of calls to make every
agent know the secret of every other agent; however it is also capable of
finding sequences of calls that lead to a situation in which every agent knows
that every agent is a secret. \textbf{TODO: Find applications for this}. 

Given that our software solves just the epistemic planning problem and not
strictly the gossip problem, it can plan for any appropriate models. There is no
other software currently that solves this problem.  

\newpage

\section{Background}

\subsection{Dynamic Epistemic Logic}

\subsubsection{Epistemic Logic}

Epistemic Logic is the logical language that we use to reason about knowledge.
It is a modal logic; a logic with some operator, that can be used to model the
passage of time, knowledge, obligation, or any other modality. The essential
reference on epistemic logic is \cite{ReasoningAboutKnowledge}, and it is from
here that most of the information in this section comes. 
  
If we have some set of agents $A$ and some set of propositions $\Lambda$, then
we define the language of epistemic logic over this set of propositions,
$\mc{L}(\Lambda)$, with the following BNF;


\begin{equation*}
  \phi ::= \top \mid p \mid \neg \phi \mid \phi \land \phi \mid K_i \phi
\end{equation*}

\noindent where $p \in \Lambda$ and $i \in A$. We also can define false,
conjunction and implication in the classic way. We read $K_i \phi$ as ``agent
$i$ knows that $\phi$ is true''. We can also define the dual to $K$, in the
classic way as $\widehat K_i \phi ::= \neg K_i \neg \phi$. We read this as
``agent $i$ considers it possible that $\phi$ is true''. We can give our
epistemic logic a semantics through use of \textit{Kripke models}.

\bigskip

A Kripke model $\mc{M}$ over a set of agents $I$ and a set of propositions
$\Lambda$ is a triple $(W, R, V)$, where $W$ is a \textbf{(maybe)} finite set of
worlds, $R$ is a set of binary relations over $W$ indexed by an agent, such that
$R_i \subseteq W \times W$, and $V : W \rightarrow \mc{P}(\Lambda)$ is a
valuation function that associates to every world in $W$ some set of
propositions that are true at it.

For epistemic logic, we think of $R_i$ as being the set of pairs of worlds that
an agent $i$ cannot distinguish between, and thus considers possible. In our
semantics, we use this relation to define knowledge in terms of possibility;
agent $i$ knows that something is true if it's true at all of the worlds that
$i$ cannot distinguish between.

\bigskip

When giving a semantics to a formula on a Kripke model, we need to use a
\textit{pointed Kriple model}. This is just a pair $(\mc{M}, w)$ where $w$ is a
world of $\mc{M}$. Then we read $(\mc{M}, w) \models \phi$ as ``$w$ satisfies
$\phi$''. We define the evaluation as follows:

\begin{align*}
  (\mc{M}, w) & \models \top \\
  (\mc{M}, w) & \models p \text{ iff } p \in V(w) \\
  (\mc{M}, w) & \models \neg \phi \text{ iff } (\mc{M}, w) \not \models \phi \\
  (\mc{M}, w) & \models \phi \land \psi \text{ iff } (\mc{M}, w) \models \phi \text{ and } (\mc{M}, w) \models \psi \\
  (\mc{M}, w) & \models K_i \phi \text{ iff for all $v$ such that } (w, v) \in R_i, (\mc{M}, v) \models \phi 
\end{align*}

\bigskip 

We need to give some properties to our knowledge operator in order to better
understand it. We make all of our relations $R_i$ equivalence relations. This
means three things;

\begin{itemize}
\item $R_i$ is \textit{reflexive}; for all $w \in W$, $(w, w) \in R_i$.
\item $R_i$ is \textit{symmetric}; for all $w, v \in W, (w, v) \in R_i$ iff $(v,
  w) \in R_i$.
\item $R_i$ is \textit{transitive}; for all $w, v, u \in W$ if $(w, v) \in R_i$
  and $(v, u) \in R_i$, then $(w, u) \in R_i$.
\end{itemize}

This is done in order to convey that agent $i$ considers world $v$ possible from
world $w$ if in both $w$ and $v$ agent $i$ has the same information; that is,
they are indistinguishable to the agent.

It is identical to say that our relations $R_i$ are equivalence relations, as it
is to say that our model is an \textsf{S5} model. This is defined as a model in
which the modal operator $K$ obeys the following axioms:

\begin{itemize}
\item \textsf{K}: $K (\phi \rightarrow \psi) \rightarrow (K \phi \rightarrow K
  \psi)$
\item \textsf{T}: $K \phi \rightarrow \phi$
\item \textsf{5}: $\widehat K \phi \rightarrow K \widehat K \phi$
\end{itemize}

These axioms hold independent of which agent's knowledge we are reasoning about. 

\subsubsection{Event Models}
\label{sec:Event Models}

Public announcement logic was the first development in epistemic logic to
support information change in epistemic logic, and is described in \cite{PAL}.
However, in public annoucement logic, we may only model truthful, public
communications; but we all know that there are many other types of communication
and events after which some information has changed. An agent may communicate
with another agent in a private phone call, or may be lying to them;
furthermore, we may have some \textit{physical} action, like a coin flip
occuring, after which some knowledge has changed.

To model these more complicated events, we use \textit{event models}. These
treat events in a very similar way to how Kripke models treat worlds; we think
of a set of possible events that can occur, and encode the events that an agent
can tell apart. We give the modern definition of event models, as in
\cite{MalvinThesis}, and \cite{AutomataTechniques}, however these were first
defined in \textbf{Cite 1998 Baltag paper}

Formally, an event model \tmc{E} is a tuple $(E, Q, \pre, \post)$. $E$ is a finite set
of events; $Q$ is a set of relations $Q_i$ for each $i \in Ag$, such that $Q_i
\subseteq E \times E$. As before, we make all relations $Q$ equivalence
relations. $\pre : E \rightarrow \mc{L}(\Lambda) $ is the \textit{precondition
  function}; given an event $e \in E$, it returns to us a formula that has to be
true in order for $e$ to occur. $\post : E \times \Lambda \rightarrow
\mc{L}(\Lambda)$ is the \textit{postcondition function}; given an event $e \in
E$ and a proposition $p \in \Lambda$, it returns to us some formula that had to
be true at the prior state $s$ in order for $p$ to be true after event $e$
occurs at $s$. We will later give examples for these two functions.

Updating a Kripke model \tmc{M} with an event model \tmc{E} is gives us another
Kripke model $\mc{M} \times \mc{E} ::= (W', R', V')$, where:

\begin{align*}
  W'   &::= \left\{(w, e) \in W \times E \mid (\mc{M}, w) \models \pre(e)\right\} \\
  R_i' &::= \left\{((w, e), (v, f)) \mid (w, v) \in R_i, (e, f) \in Q_i \right\} \\
  V'(w, e) &::= \left\{ p \in \Lambda \mid (\mc{M}, w) \models \post(e, p) \right\}
\end{align*}

We see that it is the postcondition function that allows for factual change;
that is, the update of what is true at a state given the occurence of some
event. 

\subsection{The Gossip Problem}

Gossip is a procedure for spreading secrets around a group of agents, where the
agents are commonly displayed as nodes in a graph and the ability of one agent
to contact another displayed as an edge between two nodes. Gossip was first put
forward in \cite{Tijdeman:1971}, where the network is a complete graph; all
agents can contact one another. One question here was to find how many calls are
needed for every agent to learn the secret of every other agent. We will
henceforth describe an agent knowing the secret of every other agent as this
agent being an \textit{expert}. It was quickly proved (\cite{TelephoneDisease},
\cite{GandT}) that this number, for a network where the number of agents $n$ is
greater than 4, is $2n - 4$.
 
\subsubsection{Dynamic Gossip}

Dynamic Gossip is a variant of the classical gossip problem, in which we start
off with an incomplete graph, representing the fact that the agents have only
the phone numbers of some of the other agents. In this case, when two agents
talk on the phone, they also exchange all of the phone numbers that they know as
well as the secrets that they know.

\subsubsection{Protocols}

The gossip problem, as we have mentioned so far, can rely on some central
scheduler to tell the agents what call to make, and lets them know when to stop.
However in distributed computing, methods that do not require this central
authority are desirable. In such a situation, the agents need to have some form
of rules to follow to decide how to behave and who to call next. This is the
motivation for a \textit{gossip protocol}, which are short conditions that must
be fulfilled in order for an agent to make a specific call. These protocols were
first proposed in \cite{EPfDG}, \cite{KnowledgeandGossip}, and some exemplar
ones are:

\begin{itemize}
\item \textsf{ANY} - If $x$ knows the phone number of $y$, $x$ may call $y$.
\item \textsf{LNS} - If $x$ knows the phone number of $y$ and $x$ does not
    know the secret of $y$, then $x$ may call $y$.
\end{itemize}

In this thesis, we do not study the distributed gossip problem; rather, a
version with a central authority that surveys the network topology and then
decides which agent is allowed to make a call, and also who they will call.
However, these protocols do still have use for us. \textsf{ANY} allows for
infinite call sequences - for example, one where agent $a$ just repeatedly calls
$b$, whereas all of the call sequences induced by \textsf{LNS} are of finite
length. In the long run this does not really matter; both \textsf{ANY} and
\textsf{LNS} have runtime expected execution length in $O(n \log n)$
(\cite{DynamicGossip}), yet in our implementation tests performed with
\textsf{LNS} took considerably less time than \textsf{ANY}. For this pragmatic
reason \textsf{LNS} is often used in this thesis.

It should also be noted that there are certain classes of graphs for which
\textsf{LNS} cannot induce a successful call sequence, yet \textsf{ANY} can
(\cite{DynamicGossip}). However, this thesis does not investigate this topic,
and as such this will no longer be mentioned. 

\subsubsection{Formalisation}

We now go on to formalise some of the ideas mentioned so far in this section.
The definitions of gossip graphs are classic and can be found in all of the
related literature (e.g. \cite{DynamicGossip}, \cite{MalvinThesis})

\bigskip

We formally denote a gossip graph \tmc{G} with a triple $(A, N, S)$. $A$ is a
finite set of agents in the graph; $N \subseteq A \times A$ is a set of ordered
pairs of agents such that $(u, v) \in N$ (or $Nuv$) iff $u$ knows the phone
number of $v$. $S \subseteq A \times A$ is a set of ordered pairs of agnets such
that $(u, v) \in S$ (or $Suv$) iff $u$ knows the \textit{secret} of $v$.

We have that for all gossip graphs, for any agent $a$, $(a, a) \in N$ and $(a, a)
 \in S$, expressing that any agent always knows their own phone number and
 secret. 

\subsection{Planning}

Automated planning is the process of computing which set of events must occur to
take a system from some given initial state to some successful state. Such a
system is defined as a triple $\Sigma = (S, A, \gamma)$, where:

\begin{itemize}
\item $S$ is some set of states;
\item $A$ is some set of \textit{actions};
\item $\gamma : S \times A \hookrightarrow S$ is a state-transition function. It
  is partial; for $s \in S, a \in A$, either $\gamma(s, a) \in S$ or it is
  undefined. 
\end{itemize}

Then an instance of the planning problem is a triple $(\Sigma, s_i, S_g)$,
where;

\begin{itemize}
\item $\Sigma$ is a planning system;
\item $s_i \in S$ is some initial state;
\item $S_g \subseteq S$ is some set of goal states.  
\end{itemize}

A \textit{solution} to the planning problem is some ordered set of actions
${a_0, a_1, \ldots, a_n}$ such that $\gamma(\gamma(\ldots \gamma(s_0, a_0)
\ldots ,a_{n-1}) ,a_n) \in S_g$. 

Note that we call a planning problem \textit{multi-agent} if the number of
agents in the system is greater than 1, and \textit{single-agent} if the number
of agents is equal to 1. 

\subsubsection{Epistemic Planning}

The dynamic epistemic logic community has recently been investigating a special case
of planning, namely \textit{epistemic} planning (\cite{BolanderEP},
\cite{UndecidabilityEP}). This is planning where we may have some initial
epistemic state (e.g. agent $a$ knows $\phi$), some actions that update these
epistemic states, and some accepting epistemic state (e.g. agent $b$ knows
$\psi$). It is not hard to see how this can be applied to the gossip problem.

We give a formal definition of the epistemic planning problem that slightly
differs from convention, however with this definition and those from the
literature are equivalent. Then the epistemic planning problem is as follows;
given a pointed epistemic model $(\mc{M}, w)$ and an event model $\mc{E}$, and
some goal formula $\phi$, find some set of events ${e_1, e_2, \ldots, e_n}$ such
that $(\mc{M}, w) \otimes (\mc{E}, e_1) \otimes \ldots \otimes (\mc{E}, e_n)
\models \phi$. The \textit{propositional epistemic planning problem} is the
restriction of this to event models with pre- and post-condition functions whose
codomains are in the propositional fragment of \tmc{L}; that is, they do not
contain the modal operator $K$. These event models are what we call
propositional event models. 

It is proven in \cite{BolanderEP} that the multi-agent epistemic planning
problem is undecidable for an aribtrary system. However, placing certain
restrictions on the system used yields decidability (\cite{DecidabilityEp},
\cite{AutomataTechniques}). One particularly important result is that the
propositional epistemic planning problem is decidable; indeed, it is this result
that this thesis relies on. 

\bigskip \bigskip \bigskip

In this thesis, we focus on solving the epistemic planning problem by means of
the automata constructions described in \cite{AutomataTechniques}. These
methods, and the resulting piece of software associated with this thesis, are
unique in that they will work for any epistemic model and (propositional) event
model. This unfortunately means that we cannot plan for situations like muddy
children or drinking logicians (\cite{DEMO-S5}) as they require epistemic pre-
or post-conditions. 


\subsection{Existing Tools}

We now give an overview of existing software in the realm of model checking or
planning for epistemic systems.

\subsubsection{DEMO-S5}

DEMO-S5 (\cite{DEMO-S5}) is a model checker for epistemic models, limited to
$S5$ models. It is also limited in that it only supports events that are either
public announcements (e.g. an agent telling every other agent some statement) or
publicly observable factual change (e.g. the flip of a coin, where the result is
seen by every agent).

It performs the task of model checking by taking an epistemic model and a
formula representing either the announcement or the fact that changed, and
updating the model with the event represented by the formula. The definition of
the update used is very similar to the update of an epistemic model with an
event model as defined in Section \ref{sec:Event Models}. The given events are
applied, and at this point we check if we're in a successful state or not.

\bigskip

Unfortunately we cannot use this to model check a gossip problem, as events in
the gossip problem are neither of these; they are private one-to-one
communications. Furthermore, the software is incapable of planning; simply
checking. Despite this, the software was incredibly useful in our project in
order to aid understanding of epistemic and event models. Indeed, the
formalisation of epistemic and event models demonstrated here was used in the
code associated with this thesis.

\subsubsection{Gossip}

\cite{GithubGossip} is another model checker, however now for strictly the
gossip problem. This program has a significant advantage over the other two
pieces of software; namely that it is capable of planning. It does this by
generating all of the possible sequences of calls on the graph and then checking
which of these are successful (i.e., after execution of all of the calls the
graph is in some successful state) and which are not. It also has further
capabilities for studying protocols deeply, however these are not relevant to
our thesis.

Although the methods used within this software are very different to the ones
used in our implementation, this system proved to be very useful for testing
purposes, due to its simplicity of use. The results returned by our software
during testing were verified using this system. Further elaboration on this will
be given in the evaluation section of this thesis.

One limitation of this system is that is may only handle gossip states, and not
generic epistemic models. Also limiting is that it enumerates all possible call
sequences from the initial state; we are only interested in successful ones.
This means that we have the possibility of lots of wasted computation if we need
to validate lots of unsuccessful paths before we get to a successful one. 

\subsubsection{SMCDEL}

SMCDEL is the most sophisticated of the three pieces of software. A technical
report is given in \cite{SMCDEL}, whilst a lot of the underlying theory is in
\cite{MalvinThesis}. The main difference is that it uses \textit{symbolic model
  checking}, a method put forward in \cite{SymbolicModelChecking}. This gives a
much more efficient implementation \textbf{why}?, as can be seen in the
Chapter 4 of \cite{MalvinThesis}.

This software is capable of efficiently model checking all classes of epistemic
models, and also has capacity for planning; however this side of the program is
not well-displayed, and it is unclear precisely how to use it. Furthermore, due
to a reasonably unpleasant interface we choose not to use this software for
benchmarking and instead use the simpler \cite{GithubGossip}. 

\subsection{Uniform Strategies}

In this thesis, we use a lot of ideas from \cite{AutomataTechniques}. This paper
puts forward a method for epistemic planning, through use of automata
representing states of the model and events in the event model as the states and
transitions respectively. This then references a process in
\cite{UniformStrategies} for the creation of an automata which has a set of the
other indistinguishable states baked into the states of the automata. This is a
very useful thing for our context, as it means that we can evaluate formulas of
the form $K_a \phi$ \textit{positionally}; that is, we need only to look at the
state to be able to evaluate the formula. This is in contrast to the
alternative, which is to check our current state then compute the possible call
sequences that are indistinguishable from our current one, and then go and check
there too, and so on.

The process in \cite{UniformStrategies} is very verbose and is beyond the scope
of this thesis; however, in order to illustrate the fact that our algorithm is a
special case of the process, we give a brief introduction to the process and its
theory. We slightly change some of the definitions to lend itself better to our
scenario. The setting is game theory; hence the frequent references to plays and
strategies.

\subsubsection{Game Arenas}

A game with \textit{imperfect information} is a game in which the players have
some uncertainty concerning hte current configuration of the game (for example
Poker; a player does not know which cards are in the other players' hands). A
player in such a game cannot plan to play differently in a situation she cannot
distinguish; hence we have to define her strategy \textit{uniformly} across
situations she cannot distinguish. 

We consider two-player turn-based games played on a some graph, where the
vertices are labelled with propositions. These propositions hold some useful
information about the state; it could be what people know about it, or some fact
about the environment the player is in and so on. This set of propositions will
be referred to as $AP$. 

Then a game arena is a structure $\mc{G} = (V, E, v_I, l)$ where $V = V_1 \uplus
V_2$ \footnote{We use $\uplus$ here to indicate that this is a partition} is a
set of positions split between those of Player 1 ($V_1$) and those of Player 2
($V_2$). $E \subseteq (V_1 \times V_2) \cup (V_2 \times V_1)$ is the set of
edges, $v_I \in V$ is the initial position and $l : V \rightarrow \mc{P}(AP)$ is
a valuation function, which maps each position to the finite set of propositions
that are true at it.

\subsubsection{Transducers}

We give a quick recap of transducers, as they are used heavily in the next two
sections. A transducer is like a nondeterministic finite automaton with two
tapes; an \textit{input} tape and an \textit{output} tape. The transducer reads
an input finite wood on its input and writes a finite word on its output tape.
Hence a transducer defines a binary relation. Relations recognised by a
transducer are called \textit{regular} or \textit{rational} relations. 

A transducer is a 6-tuple $T = (Q, \Sigma, \Gamma, I, F, \Delta)$, where $Q$ is
a finite set of states, $\Sigma$ is the input alphabet, $\Gamma$ is the output
alphabet, $I \subseteq Q$ is a finite set of initial states, $F \subseteq Q$ is
a finite set of final states, and $\Delta \subseteq Q \times \left( \Sigma \cup
  \{\epsilon\} \right) \times \left( \Gamma \cup \{\epsilon\} \right) \times Q$
is the transition function.

$(q, a, b, q') \in \Delta$ means that the transducer can move from state $q$ to
state $q'$ by reading $a$ from the input tape and writing $b$ to the output
tape. Then we can define the extended transition relation $\Delta^\ast$ as the
smallest relation satisfying:

\begin{itemize}
\item for all $q \in Q$, $(q, \epsilon, \epsilon, q) \in \Delta^\ast$
\item if $(q, w, w', q') \in \Delta^\ast$ and $(q', a, b, q'') \in \Delta$, then
  $(q, w . a, w' . b, q'') \in \Delta^\ast$
  
\end{itemize}

We can see $\Delta^\ast$ as the transitive closure of $\Delta$. We abbreviate
$(q, w, w', q') \in \Delta^\ast$ to $q \rsarrow_{w \mid w'} q'$ in the rest of
this section.

Finally, we say that the relation recognised by some transducer $T$ is

\begin{align*}
  [T] ::= \left\{ (w, w') \mid w \in \Sigma^\ast, w' \in \Gamma^\ast, \exists q_F \in F, \exists q_i \in I, q_i \rsarrow_{w \mid w'} q_F \right\}
\end{align*}

\subsubsection{The Powerset Arena}
\label{sec:PowersetArena}

In games with imperfect information, the information set of a player after a
certain play is the set of positions she may possibly be in, consistent with
what she has observed\footnote{For instance in a game of poker with one deck of cards, a
player may have no idea what the other players have in their hands except that
they know they don't have the cards the player has in their own hands, nor the
cards face-up on the table.}. We can define a similar notion in our setting, and
we show that this is sufficient to build a powerset arena in which formulas of
the form $K_a \phi$, where $\phi$ is propositional, can be evaluated positionally. 

For an arena \tmc{G} and a transducer $T$ over finite sequences of events $e_i \in
E$, we construct this automata $\widehat{\mc{G}}$ in which we can evaluate
formulas of the form $K_i \phi$... 

Our new information set after a move occurs cannot be computed knowing only the
previous information set and the new position; we need to simulate the
nondeterministic execution of $T$, taking as input the sequence of positions
played and writing as output the related plays. Precisely, we need two things;
the set of states the transducer may be in after reading the sequence of
positions played so far, and for each of these states the set of possible last
positions written on the output tape. We need only remember the last letter and
not the whole tape because the information set we aim to compute is just the set
of the last positions of related plays.

Then our positions are of the form $(v, S, Last)$, where $v \in V$, $S \subseteq
Q$, where $Q$ is the set of states in the transducer and $S$ is the set of
possible current states of $T$, and $Last : S -> \mc{P}(V)$\footnote{It may be
  more helpful to think of this as something a bit more tangible than a
  function, e.g. a list of tuples $(S, [P])$} associates to a state $q \in S$
the set of the possible last positions on the output tape fo $T$ if the current
state is $q$. The transitions in this arena follow those in \tmc{G}, except we
now maintain the additional information about the configuration of the
transducer.

To construct the initial position $\widehat{v_I} = (v_I, S_I, Last_I) \in
\widehat{\mc{G}}$, we need to simulate the execution of $T$ starting from its
initial state and reading $v_I$. To do this, we introduce an artificial position
$\widehat{v_{-1}} = (v_{-1}, S_{-1}, Last_{-1})$, where $v_{-1} \not \in V$ is
some fresh position, $S_{-1} = \{q_i\}$ where $q_i$ is the initial state of the
transducer because before starting the transducer is in its initial state, and
$Last_{-1} (q_i) = \emptyset$ because we have nothing written on the output
tape.  

\bigskip

We now come onto defining \tmc{G}. Let $\mc{G} = (V, E, v_I, l)$ be an arena and
$T = (Q, V, q_i, Q_F, \Delta)$ be an FST. Then we define the arena
$\widehat{\mc{G}} = (\widehat{V}, \widehat{E}, \widehat{v_I}, \widehat{l})$ as:

\begin{itemize}
\item $\widehat{V} = V \times \mc{P}(Q) \times (Q \rightarrow \mc{P}(V))$
\item $(u, S, Last) \widehat{\rightarrow} (v, S', Last')$ if
  \begin{itemize}
  \item $u = v_{-1} \text{ and } v = v_I, \text{ or } u \rightarrow v$,
  \item $S' = \left\{q' \mid \exists q \in S, \exists \lambda' \in V^\ast, q
      \rsarrow_{v \mid \lambda'} q' \right\}$ and
  \item $Last' (q') = \left\{ v' \mid \exists q \in S, \exists \lambda' \in
      V^\ast, q \rsarrow_{v \mid \lambda' \circ v'} q', \text{ or } q \rsarrow_{v \mid
        \epsilon} q' \text{ and } v' \in Last(q) \right\}$
  \end{itemize}
\item $\widehat{v_I}$ is the only $\widehat{v} \in \widehat{V}$ such that
  $\widehat{v}_{-1} \widehat{\rightarrow} \widehat{v}$.
\item $\widehat{l}(\widehat{v}) = l (v)$ if $\widehat{v}= (v, S, Last)$. 
\end{itemize}

The definition of transitons is quite complicated, and as such we give a high-level
explanation of it. Regarding the definition of the transitions,
the first point means that our transitions in $\widehat{E}$ follow those in $E$,
except for the transition leaving $\widehat{v_{-1}}$, which we use to define
$\widehat{v_I}$. 

The second point expresses that when we move from $u$ to $v$ in \tmc{G}, we give
$v$ as input to the transducer. Then the set of states that we can be in, that
is, $S'$, is the set of states that can be reached from some previous possible
state in $q \in S$ by reading $v$ on the input tape and outputting some sequence
$\lambda'$.

Finally, the third point expresses that if some position $v'$ is at the end of
the output tape after the transducer reads $v$ and reaches $q$, then it's either
because while reading $v$ the last letter it wrote is $v'$, or it wrote nothing
and $v'$ was already at the end of the output tape before reading $v$. 

Finally, we say that $\widehat{v}_I$ is the only successor of
$\widehat{v}_{-1}$, and that the valuation of a position in the powerset arena
is the valuation of the underlying position in the original arena. 

\subsubsection{Lifting Transducers}

We can keep on repeating this process, creating a power-powerset arena
$\widehat{\widehat{G}}$. However we first need to lift our transducer $T$ where
$[T] \subseteq Plays_\ast \times Plays_\ast$ to a transducer $\widehat{T}$ where
$[\widehat{T}] \subseteq \widehat{Plays_\ast} \times \widehat{Plays_\ast}$.

We write $T\downarrow$ for the transducer that computers the bijective function
$f$ that maps a play $\widehat{p} \in \wh{Plays_\ast}$ to the underlying play $p
\in Player_\ast$, and $T\uparrow$ for the deterministic transducer that computes
$f^{-1}$. Both can be easily constructed from our powerset arena $\wh{G}$.

Then the lift of a transducer $T$ is $\wh{T} = T\downarrow \circ T \circ
T\uparrow$.

Once we have the transducer $\wh{T}$, we can repeat the process in Section
\ref{sec:PowersetArena} with $\wh{G}$ to get $\wh{\wh{G}}$, and so on ad
infinitum. $\wh{\wh{G}}$ would allow us to positionally check formulae of the
form $K_i K_j \phi$.

\newpage

\section{Algorithm}

We now give a description of the algorithm we put forward in order to plan for
epistemic models.

\textbf{TODO: Add some more to this}.

\subsection{\mestar}

%%% Bibliography %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\printbibliography[title={Bibliography}]



\end{document}
